{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "ai_final_loss_plot_aug.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.10"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5C9csU--qvdg",
        "outputId": "4249c6f6-2a06-411e-b003-615fd9aa467b"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qCZ7dyCOa1k_",
        "outputId": "7c893596-219a-4ca5-cfdc-6a93bbfe9ab1"
      },
      "source": [
        "!pip install timm"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: timm in /usr/local/lib/python3.7/dist-packages (0.4.12)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.7/dist-packages (from timm) (0.11.1+cu111)\n",
            "Requirement already satisfied: torch>=1.4 in /usr/local/lib/python3.7/dist-packages (from timm) (1.10.0+cu111)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch>=1.4->timm) (3.10.0.2)\n",
            "Requirement already satisfied: pillow!=8.3.0,>=5.3.0 in /usr/local/lib/python3.7/dist-packages (from torchvision->timm) (7.1.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from torchvision->timm) (1.19.5)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lXHTAvOINTaY"
      },
      "source": [
        "import sys\n",
        "sys.path.append('drive/MyDrive/ai/final/petfinder-pawpularity-score')\n",
        "### <디렉토리 설정하는 곳> (검색용) ################################################################################################\n",
        "### 지금 위의 코드는\n",
        "### 이 코드파일(ai_final_loss_plot.ipynb)과 함께 다른 데이터셋 관련파일들(test, train, sample_submission.csv, test.csv, train.csv)을 \n",
        "### 구글드라이브 안의 /ai/final/petfinder-pawpularity-score 디렉토리에 넣어줘야, 코드가 돌아가도록 되어있다.\n",
        "###\n",
        "### 위에서 말한 코드파일과 데이터셋 관련 파일들의 위치를 바꾸고 싶으면, \n",
        "### 위의 sys.path.append() 안의 인자를 'drive/MyDrive/(구글 드라이브 내의 디렉토리 주소)' 로 바꿔주면 된다.\n",
        "####################################################################################################################################"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RKfM4Oi9Nvgl"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import os\n",
        "import torch\n",
        "\n",
        "import cv2\n",
        "from os import path\n",
        "from PIL import Image\n",
        "import torch.utils.data as data\n",
        "from torchvision import models, transforms\n",
        "import torch.nn as nn\n",
        "from tqdm import tqdm\n",
        "import torch.nn.functional as F\n",
        "import h5py\n",
        "import timm\n",
        "import shutil\n",
        "\n",
        "from sklearn import metrics\n",
        "from sklearn.metrics import mean_squared_error\n",
        "from sklearn.metrics import median_absolute_error\n",
        "from sklearn.metrics import mean_squared_log_error\n",
        "from sklearn.metrics import mean_absolute_error\n",
        "from sklearn.metrics import r2_score\n",
        "from sklearn.metrics import explained_variance_score\n",
        "from scipy.stats import pearsonr"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HCOUGUmnOxJD",
        "outputId": "29ed0491-e5f4-48d2-d344-42ce280d9419"
      },
      "source": [
        "class args:\n",
        "### <배치크기, 에폭수 설정하는 곳 (검색용)> ######################\n",
        "### 지금은 batch_size 값 32, 에폭수 10으로 되어있다. \n",
        "##################################################################\n",
        "\n",
        "    seed = 22\n",
        "    batch_size = 64\n",
        "    epochs = 5\n",
        "    image_size = 384  # scale shorter end of image to this size and centre crop\n",
        "    central_fraction = 0.875  # only take this much of the centre when scaling and centre cropping\n",
        "    load_img = False # whether load img or not\n",
        "    workers = 2\n",
        "    feature_extract = True\n",
        "\n",
        "def seed_torch(seed):\n",
        "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
        "    np.random.seed(seed)\n",
        "    torch.manual_seed(seed)\n",
        "    torch.cuda.manual_seed(seed)\n",
        "    torch.backends.cudnn.deterministic = True\n",
        "    print(\"seed: \", seed)\n",
        "\n",
        "seed_torch(args.seed)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "seed:  22\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mDZnN_e9HEfZ"
      },
      "source": [
        "def makedirs(path): \n",
        "  if os.path.exists(path):\n",
        "    shutil.rmtree(path)\n",
        "  try: \n",
        "    os.makedirs(path) \n",
        "  except OSError: \n",
        "    if not os.path.isdir(path): \n",
        "      raise"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tbKoHmYQPA-C"
      },
      "source": [
        "dir_path = 'drive/MyDrive/ai/final/petfinder-pawpularity-score'\n",
        "### <디렉토리 설정하는 곳> (검색용) ################################################################################################\n",
        "### 지금 위의 코드는\n",
        "### 이 코드파일(ai_final_loss_plot.ipynb)과 함께 다른 데이터셋 관련파일들(test, train, sample_submission.csv, test.csv, train.csv)을 \n",
        "### 구글드라이브 안의 /ai/final/petfinder-pawpularity-score 디렉토리에 넣어줘야, 코드가 돌아가도록 되어있다.\n",
        "###\n",
        "### 위에서 말한 코드파일과 데이터셋 관련 파일들의 위치를 바꾸고 싶으면, \n",
        "### 위의 sys.path.append() 안의 인자를 'drive/MyDrive/(구글 드라이브 내의 디렉토리 주소)' 로 바꿔주면 된다.\n",
        "####################################################################################################################################\n",
        "\n",
        "cached_dir = path.join(dir_path, 'cached_data')\n",
        "train_img_dir = path.join(dir_path, 'train')\n",
        "test_img_dir = path.join(dir_path, 'test')\n",
        "aug_img_dir = path.join(dir_path, 'train_aug')\n",
        "\n",
        "df_train = pd.read_csv(path.join(dir_path, 'train.csv'))\n",
        "df_test = pd.read_csv(path.join(dir_path, 'test.csv'))\n",
        "\n",
        "train_img_paths = [path.join(train_img_dir, f\"{img_id}.jpg\") for img_id in df_train[\"Id\"].values]\n",
        "test_img_paths = [path.join(test_img_dir, f\"{img_id}.jpg\") for img_id in df_test[\"Id\"].values]\n",
        "\n",
        "# 경로에 파일 없으면 생성 있으면 지우고 재생성 \n",
        "makedirs(aug_img_dir)"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4T-t9EkFPWZj",
        "outputId": "8b8b520c-b0c3-43be-a8e0-f3d4b4585d74"
      },
      "source": [
        "property_names = [col for col in df_train.columns if col not in ['Id','Pawpularity']]\n",
        "property_names # 12 properties\n",
        "\n",
        "# train metda data\n",
        "train_meta_X = df_train[property_names]\n",
        "train_Y = df_train['Pawpularity']\n",
        "\n",
        "# test metda data\n",
        "test_id = df_test['Id']\n",
        "test_meta_X = df_test.drop('Id',axis=1)\n",
        "test_meta_X.shape"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(8, 12)"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m7JZLbLmPu7J"
      },
      "source": [
        "class PawpularDataset(data.Dataset):\n",
        "    def __init__(self, image_data, meta_features, labels, img_paths, augmentations=None):\n",
        "        super(PawpularDataset, self).__init__()\n",
        "        self.load_img = False\n",
        "        self.image_data = image_data\n",
        "        self.meta_features = meta_features\n",
        "        self.labels = labels\n",
        "        self.augmentations = augmentations\n",
        "        self.image_paths = img_paths\n",
        "        if self.augmentations is not None:\n",
        "            self.load_img = True\n",
        "\n",
        "\n",
        "    def __getitem__(self, item):\n",
        "        if self.load_img:\n",
        "            image = cv2.imread(self.image_paths[item])\n",
        "            image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
        "            \n",
        "            augmented = self.augmentations(image=image)[\"image\"]\n",
        "            \n",
        "            #augmentation 저장\n",
        "            save_aug(augmented,item)\n",
        "\n",
        "            image = np.transpose(augmented, (2, 0, 1)).astype(np.float32)\n",
        "        else:\n",
        "            image = self.image_data[item]\n",
        "\n",
        "        meta = self.meta_features[item]\n",
        "        label = self.labels[item]\n",
        "        return image.astype('float32'), meta.astype('float32'), label\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.labels)\n",
        "\n",
        "def save_aug(image, item):\n",
        "    global aug_img_dir\n",
        "    \"\"\"\n",
        "    Function to Plot the Transformed Images\n",
        "    \"\"\"\n",
        "    #print(label)\n",
        "    image = cv2.cvtColor(image, cv2.COLOR_RGB2BGR)\n",
        "\n",
        "    path = aug_img_dir+ \"/\" +str(item)+\".jpg\" \n",
        "    # print(path)\n",
        "    cv2.imwrite(path, image)\n",
        "    #Unnormalize\n",
        "    # plt.imshow(image)\n",
        "    # plt.show()\n",
        "\n",
        "def get_loader(split, features, meta_data, labels, img_paths=[], batch_size=args.batch_size, augmentations=None):\n",
        "    \"\"\" Returns a data loader for the desired split \"\"\"\n",
        "    dataset = PawpularDataset(features, meta_data, labels, img_paths, augmentations)\n",
        "    loader = torch.utils.data.DataLoader(\n",
        "        dataset,\n",
        "        batch_size=batch_size,\n",
        "        shuffle=True if split != 'test' else False,  # only shuffle the data in training\n",
        "        pin_memory=True,\n",
        "        num_workers=args.workers,\n",
        "    )\n",
        "    return loader"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R5YxTauMPzUj"
      },
      "source": [
        "import albumentations\n",
        "\n",
        "def get_augmentations(train=True):\n",
        "    if train:\n",
        "        return albumentations.Compose(\n",
        "            [\n",
        "                ## 크기조절\n",
        "                albumentations.Resize(args.image_size, args.image_size, p=1),\n",
        "                ## 좌우 반전\n",
        "                albumentations.HorizontalFlip(p=0.5),\n",
        "                ## 상하 반전\n",
        "                ##albumentations.VerticalFlip(p=0.5),\n",
        "                ## 회전\n",
        "                albumentations.Rotate(limit=45, p=0.7),\n",
        "            ]\n",
        "        )\n",
        "    else:\n",
        "        return albumentations.Compose(\n",
        "            [\n",
        "                albumentations.Resize(args.image_size, args.image_size, p=1),\n",
        "#                 albumentations.Normalize(\n",
        "#                     mean=[0.485, 0.456, 0.406],\n",
        "#                     std=[0.229, 0.224, 0.225],\n",
        "#                     max_pixel_value=255.0,\n",
        "#                     p=1.0,\n",
        "#                 ),\n",
        "            ]\n",
        "        )\n",
        "\n",
        "augmentations = get_augmentations(train=True)\n",
        "trainval_loader = get_loader('trainval', None, train_meta_X.values, train_Y.values.astype('float32'), train_img_paths,augmentations=augmentations)\n",
        "\n",
        "augmentations = get_augmentations(train=False)\n",
        "test_loader = get_loader('test', None, test_meta_X.values, torch.zeros(len(test_img_paths)), test_img_paths, augmentations=augmentations)"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LOqmF0uoP9uS"
      },
      "source": [
        "def set_parameter_requires_grad(model, feature_extracting):\n",
        "    if feature_extracting:\n",
        "        for param in model.parameters():\n",
        "            param.requires_grad = False\n",
        "\n",
        "### <인공지능 모델 아키텍처 설정하는 곳> (검색용) ################################################################################################\n",
        "### 아래에는 다음과 같은 모델 아키텍처를 정의하는 class 코드가 있음.\n",
        "### \n",
        "### PretrainedCNN         - 이미 학습되어있는 \"resnet\" 모델을 불러오고, 마지막 layer에 metadata를 input data로 넣어주도록 고쳐준 모델\n",
        "### BaseCNN               - CNN 을 활용한 모델, 마지막 layer에 metadata를 input data로 넣어주도록 고쳐준 모델\n",
        "### BaseMLP               - MLP 를 활용한 모델, 마지막 layer에 metadata를 input data로 넣어주도록 고쳐준 모델\n",
        "### PretrainedTransformer - 이미 학습되어있는 다양한 모델들 중 하나를 불러오고, 마지막 layer에 metadata를 input data로 넣어주도록 고쳐준 모델\n",
        "###\n",
        "### 이 아래에 class 중에서 직접 수정해보면 좋은 것은, BaseCNN , BaseMLP class 부분임.\n",
        "### BaseCNN 은 CNN 실습했을때처럼 수정하면 될 듯\n",
        "### BaseMLP 는 MLP 실습했을때처럼 수정하면 될 듯\n",
        "###\n",
        "### 한편, PretrainedTransformer class 를 활용해도 좋음. 이미 학습되어있는 모델을 불러와서 코드를 돌려볼 수 있음. 자세한 내용은 아래 <모델 고르기> 부분에서 설명함.\n",
        "####################################################################################################################################\n",
        "\n",
        "\n",
        "\n",
        "class PretrainedCNN(nn.Module):\n",
        "    def __init__(self, model_name='resnet', use_meta=False):\n",
        "        super(PretrainedCNN, self).__init__()\n",
        "        if model_name == 'resnet':\n",
        "            self.model = models.resnet152(pretrained=True)\n",
        "            set_parameter_requires_grad(self.model, feature_extracting=True)\n",
        "            num_ftrs = self.model.fc.in_features\n",
        "        self.model.fc = nn.Linear(num_ftrs, 128)\n",
        "        self.drop = nn.Dropout(0.5)\n",
        "        self.use_meta =use_meta\n",
        "        if self.use_meta:\n",
        "            self.fc = nn.Linear(128+12, 1)\n",
        "        else:\n",
        "            self.fc = nn.Linear(128, 1)\n",
        "        \n",
        "\n",
        "    def forward(self, img_data, meta=None, targets=None):\n",
        "        x = self.model(img_data)\n",
        "        if self.use_meta:\n",
        "            x = torch.cat([x, meta], dim=1)\n",
        "        x = self.fc(self.drop(x)) # [b, o]\n",
        "        return x\n",
        "\n",
        "\n",
        "\n",
        "class BaseCNN(nn.Module):\n",
        "    def __init__(self, num_filters=[], use_meta=False):\n",
        "        super(BaseCNN, self).__init__()\n",
        "        self.conv = nn.Sequential(\n",
        "            nn.Conv2d(3, num_filters[0], kernel_size = 3, padding = 1),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(2,2),\n",
        "            nn.Conv2d(num_filters[0], num_filters[1], kernel_size = 4, stride = 1, padding = 1),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(2,2),\n",
        "        \n",
        "            nn.Conv2d(num_filters[1], num_filters[2], kernel_size = 5, stride = 1, padding = 1),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(2,2),\n",
        "            nn.Conv2d(num_filters[2] ,num_filters[3], kernel_size = 8, stride = 1, padding = 1),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(2,2),\n",
        "            \n",
        "            nn.Conv2d(num_filters[3], num_filters[4], kernel_size = 6, stride = 1, padding = 1),\n",
        "            nn.ReLU(),\n",
        "            nn.Conv2d(num_filters[4], num_filters[4], kernel_size = 6, stride = 1, padding = 1),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(2,2),\n",
        "\n",
        "            nn.Flatten(),\n",
        "            nn.Linear(12544, 1024),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(1024, 512),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(512,128)\n",
        "        )\n",
        "        # fc\n",
        "        self.use_meta = use_meta\n",
        "        self.drop = nn.Dropout(0.5)\n",
        "        if self.use_meta:\n",
        "            self.fc = nn.Linear(128+12, 1)\n",
        "        else:\n",
        "            self.fc = nn.Linear(128, 1)\n",
        "\n",
        "\n",
        "    def forward(self, img_data, meta=None, targets=None):\n",
        "        o = self.conv(self.drop(img_data)) # [b, 1, m]\n",
        "        if self.use_meta:\n",
        "            o = torch.cat([o, meta], dim=1)\n",
        "        x = self.fc(self.drop(o)) # [b, o]\n",
        "        return x\n",
        "\n",
        "\n",
        "class BaseMLP(nn.Module):\n",
        "    def __init__(self, use_meta=False, input_size=args.image_size):\n",
        "        super(BaseMLP, self).__init__()\n",
        "        # fc\n",
        "        self.use_meta = use_meta\n",
        "        self.drop = nn.Dropout(0.5)\n",
        "        self.lin = nn.Sequential(\n",
        "            nn.Linear(input_size*input_size, 2048),\n",
        "            nn.ReLU(),\n",
        "            nn.BatchNorm1d(3),\n",
        "            nn.Dropout(0.5),\n",
        "            nn.Linear(2048, 512),\n",
        "            nn.ReLU(),\n",
        "            nn.BatchNorm1d(3),\n",
        "            nn.Dropout(0.5),\n",
        "            nn.Linear(512,128)\n",
        "        )\n",
        "        if self.use_meta:\n",
        "            self.fc = nn.Linear((128*3)+12, 1)\n",
        "        else:\n",
        "            self.fc = nn.Linear(128*3, 1)\n",
        "\n",
        "\n",
        "    def forward(self, img_data, meta=None, targets=None):\n",
        "        b, c, img_size, _ = img_data.shape\n",
        "        img_data = img_data.view(b, c, img_size*img_size)\n",
        "        o = self.lin(self.drop(img_data)) # [b, 3, 128]\n",
        "        o = o.view(b, -1)\n",
        "        if self.use_meta:\n",
        "            o = torch.cat([o, meta], dim=1)\n",
        "        x = self.fc(self.drop(o)) # [b, o]\n",
        "        return x\n",
        "\n",
        "\n",
        "class PretrainedTransformer(nn.Module):\n",
        "    def __init__(self, model_name='', use_meta=False, pretrained=True):\n",
        "        super(PretrainedTransformer, self).__init__()\n",
        "        # fc\n",
        "        self.use_meta = use_meta\n",
        "        self.drop = nn.Dropout(0.5)\n",
        "        self.model = timm.create_model(model_name, pretrained=pretrained, num_classes=0, in_chans=3)\n",
        "        set_parameter_requires_grad(self.model, feature_extracting=True)\n",
        "        num_features = self.model.num_features\n",
        "\n",
        "        if self.use_meta:\n",
        "            self.fc = nn.Linear(num_features+12, 1)\n",
        "        else:\n",
        "            self.fc = nn.Linear(num_features, 1)\n",
        "\n",
        "\n",
        "    def forward(self, img_data, meta=None, targets=None):\n",
        "        x = self.model(img_data)\n",
        "        if self.use_meta:\n",
        "            x = torch.cat([x, meta], dim=1)\n",
        "        x = self.fc(self.drop(x)) # [b, o]\n",
        "        return x\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "torch.backends.cudnn.enabled = True\n",
        "torch.backends.cudnn.benchmark = True"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4Bm663fSQCCk"
      },
      "source": [
        "import matplotlib.pyplot as plt ##5\n",
        "test_loss_record = [] ##5\n",
        "mse = nn.MSELoss()  ##\n",
        "\n",
        "\n",
        "def train(model, optimizer, train_loader, val_loader, train=True, val=False, epoch=0, grad_clip=False):\n",
        "    labels, preds = [], []\n",
        "    if train:\n",
        "        #mse = nn.MSELoss() -> 이건 밖으로 빼서 전역변수로 만들었음 ##\n",
        "        train_loader = tqdm(train_loader, desc='{} E{:03d}'.format('train', epoch), ncols=0)\n",
        "        model.train()\n",
        "        for i, (img, meta_feature, label) in enumerate(train_loader):\n",
        "            img = img.cuda().float()\n",
        "            meta_feature = meta_feature.cuda()\n",
        "            label = label.cuda()\n",
        "            pred = model(img, meta_feature, label)\n",
        "\n",
        "            # loss = criterion(pred , label.view(-1,1))\n",
        "            loss = mse(pred, label.view(-1, 1))\n",
        "\n",
        "            loss.backward()\n",
        "            if grad_clip:\n",
        "                nn.utils.clip_grad_norm_(model.parameters(), 0.5)\n",
        "            optimizer.step()\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "            num = 10\n",
        "            if i % num == 0:\n",
        "                rmse_loss = pow(loss.item() , 0.5)\n",
        "                print(\"\\tTrain Epoch:{} \\tTrain Loss(RMSE): {:.6f}\".format(epoch, rmse_loss)) ##\n",
        "                test_loss_record.append(rmse_loss)\n",
        "    \n",
        "    if val:\n",
        "        model.eval()\n",
        "        val_loader = tqdm(val_loader, desc='{} E{:03d}'.format('val', epoch), ncols=0)\n",
        "        for i, (img, meta_feature, label) in enumerate(val_loader):\n",
        "            img = img.cuda().float()\n",
        "            pred = model(img, meta_feature, None)\n",
        "\n",
        "            labels.append(label.detach().cpu())\n",
        "            preds.append(pred.detach().cpu())\n",
        "\n",
        "        labels = torch.cat(labels, dim=0).numpy() # [num_seg]\n",
        "        preds = torch.cat(preds, dim=0).numpy() # [num_seg]\n",
        "\n",
        "    return labels, preds"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5TquLlHZydEl",
        "outputId": "d5f74124-2c77-48b4-9cb7-7a3841b5ccd9"
      },
      "source": [
        "### <학습된 모델 확인하기> (검색용) ######################\n",
        "### 사용할 수 있는 이미 학습된 모델들을 아래 출력해줌\n",
        "############################################################\n",
        "timm.list_models()[:]"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['adv_inception_v3',\n",
              " 'bat_resnext26ts',\n",
              " 'botnet26t_256',\n",
              " 'botnet50ts_256',\n",
              " 'cait_m36_384',\n",
              " 'cait_m48_448',\n",
              " 'cait_s24_224',\n",
              " 'cait_s24_384',\n",
              " 'cait_s36_384',\n",
              " 'cait_xs24_384',\n",
              " 'cait_xxs24_224',\n",
              " 'cait_xxs24_384',\n",
              " 'cait_xxs36_224',\n",
              " 'cait_xxs36_384',\n",
              " 'coat_lite_mini',\n",
              " 'coat_lite_small',\n",
              " 'coat_lite_tiny',\n",
              " 'coat_mini',\n",
              " 'coat_tiny',\n",
              " 'convit_base',\n",
              " 'convit_small',\n",
              " 'convit_tiny',\n",
              " 'cspdarknet53',\n",
              " 'cspdarknet53_iabn',\n",
              " 'cspresnet50',\n",
              " 'cspresnet50d',\n",
              " 'cspresnet50w',\n",
              " 'cspresnext50',\n",
              " 'cspresnext50_iabn',\n",
              " 'darknet53',\n",
              " 'deit_base_distilled_patch16_224',\n",
              " 'deit_base_distilled_patch16_384',\n",
              " 'deit_base_patch16_224',\n",
              " 'deit_base_patch16_384',\n",
              " 'deit_small_distilled_patch16_224',\n",
              " 'deit_small_patch16_224',\n",
              " 'deit_tiny_distilled_patch16_224',\n",
              " 'deit_tiny_patch16_224',\n",
              " 'densenet121',\n",
              " 'densenet121d',\n",
              " 'densenet161',\n",
              " 'densenet169',\n",
              " 'densenet201',\n",
              " 'densenet264',\n",
              " 'densenet264d_iabn',\n",
              " 'densenetblur121d',\n",
              " 'dla34',\n",
              " 'dla46_c',\n",
              " 'dla46x_c',\n",
              " 'dla60',\n",
              " 'dla60_res2net',\n",
              " 'dla60_res2next',\n",
              " 'dla60x',\n",
              " 'dla60x_c',\n",
              " 'dla102',\n",
              " 'dla102x',\n",
              " 'dla102x2',\n",
              " 'dla169',\n",
              " 'dm_nfnet_f0',\n",
              " 'dm_nfnet_f1',\n",
              " 'dm_nfnet_f2',\n",
              " 'dm_nfnet_f3',\n",
              " 'dm_nfnet_f4',\n",
              " 'dm_nfnet_f5',\n",
              " 'dm_nfnet_f6',\n",
              " 'dpn68',\n",
              " 'dpn68b',\n",
              " 'dpn92',\n",
              " 'dpn98',\n",
              " 'dpn107',\n",
              " 'dpn131',\n",
              " 'eca_botnext26ts_256',\n",
              " 'eca_efficientnet_b0',\n",
              " 'eca_halonext26ts',\n",
              " 'eca_lambda_resnext26ts',\n",
              " 'eca_nfnet_l0',\n",
              " 'eca_nfnet_l1',\n",
              " 'eca_nfnet_l2',\n",
              " 'eca_nfnet_l3',\n",
              " 'eca_swinnext26ts_256',\n",
              " 'eca_vovnet39b',\n",
              " 'ecaresnet26t',\n",
              " 'ecaresnet50d',\n",
              " 'ecaresnet50d_pruned',\n",
              " 'ecaresnet50t',\n",
              " 'ecaresnet101d',\n",
              " 'ecaresnet101d_pruned',\n",
              " 'ecaresnet200d',\n",
              " 'ecaresnet269d',\n",
              " 'ecaresnetlight',\n",
              " 'ecaresnext26t_32x4d',\n",
              " 'ecaresnext50t_32x4d',\n",
              " 'efficientnet_b0',\n",
              " 'efficientnet_b1',\n",
              " 'efficientnet_b1_pruned',\n",
              " 'efficientnet_b2',\n",
              " 'efficientnet_b2_pruned',\n",
              " 'efficientnet_b2a',\n",
              " 'efficientnet_b3',\n",
              " 'efficientnet_b3_pruned',\n",
              " 'efficientnet_b3a',\n",
              " 'efficientnet_b4',\n",
              " 'efficientnet_b5',\n",
              " 'efficientnet_b6',\n",
              " 'efficientnet_b7',\n",
              " 'efficientnet_b8',\n",
              " 'efficientnet_cc_b0_4e',\n",
              " 'efficientnet_cc_b0_8e',\n",
              " 'efficientnet_cc_b1_8e',\n",
              " 'efficientnet_el',\n",
              " 'efficientnet_el_pruned',\n",
              " 'efficientnet_em',\n",
              " 'efficientnet_es',\n",
              " 'efficientnet_es_pruned',\n",
              " 'efficientnet_l2',\n",
              " 'efficientnet_lite0',\n",
              " 'efficientnet_lite1',\n",
              " 'efficientnet_lite2',\n",
              " 'efficientnet_lite3',\n",
              " 'efficientnet_lite4',\n",
              " 'efficientnetv2_l',\n",
              " 'efficientnetv2_m',\n",
              " 'efficientnetv2_rw_m',\n",
              " 'efficientnetv2_rw_s',\n",
              " 'efficientnetv2_s',\n",
              " 'ens_adv_inception_resnet_v2',\n",
              " 'ese_vovnet19b_dw',\n",
              " 'ese_vovnet19b_slim',\n",
              " 'ese_vovnet19b_slim_dw',\n",
              " 'ese_vovnet39b',\n",
              " 'ese_vovnet39b_evos',\n",
              " 'ese_vovnet57b',\n",
              " 'ese_vovnet99b',\n",
              " 'ese_vovnet99b_iabn',\n",
              " 'fbnetc_100',\n",
              " 'fbnetv3_b',\n",
              " 'fbnetv3_d',\n",
              " 'fbnetv3_g',\n",
              " 'gc_efficientnet_b0',\n",
              " 'gcresnet50t',\n",
              " 'gcresnext26ts',\n",
              " 'geresnet50t',\n",
              " 'gernet_l',\n",
              " 'gernet_m',\n",
              " 'gernet_s',\n",
              " 'ghostnet_050',\n",
              " 'ghostnet_100',\n",
              " 'ghostnet_130',\n",
              " 'gluon_inception_v3',\n",
              " 'gluon_resnet18_v1b',\n",
              " 'gluon_resnet34_v1b',\n",
              " 'gluon_resnet50_v1b',\n",
              " 'gluon_resnet50_v1c',\n",
              " 'gluon_resnet50_v1d',\n",
              " 'gluon_resnet50_v1s',\n",
              " 'gluon_resnet101_v1b',\n",
              " 'gluon_resnet101_v1c',\n",
              " 'gluon_resnet101_v1d',\n",
              " 'gluon_resnet101_v1s',\n",
              " 'gluon_resnet152_v1b',\n",
              " 'gluon_resnet152_v1c',\n",
              " 'gluon_resnet152_v1d',\n",
              " 'gluon_resnet152_v1s',\n",
              " 'gluon_resnext50_32x4d',\n",
              " 'gluon_resnext101_32x4d',\n",
              " 'gluon_resnext101_64x4d',\n",
              " 'gluon_senet154',\n",
              " 'gluon_seresnext50_32x4d',\n",
              " 'gluon_seresnext101_32x4d',\n",
              " 'gluon_seresnext101_64x4d',\n",
              " 'gluon_xception65',\n",
              " 'gmixer_12_224',\n",
              " 'gmixer_24_224',\n",
              " 'gmlp_b16_224',\n",
              " 'gmlp_s16_224',\n",
              " 'gmlp_ti16_224',\n",
              " 'halonet26t',\n",
              " 'halonet50ts',\n",
              " 'halonet_h1',\n",
              " 'halonet_h1_c4c5',\n",
              " 'hardcorenas_a',\n",
              " 'hardcorenas_b',\n",
              " 'hardcorenas_c',\n",
              " 'hardcorenas_d',\n",
              " 'hardcorenas_e',\n",
              " 'hardcorenas_f',\n",
              " 'hrnet_w18',\n",
              " 'hrnet_w18_small',\n",
              " 'hrnet_w18_small_v2',\n",
              " 'hrnet_w30',\n",
              " 'hrnet_w32',\n",
              " 'hrnet_w40',\n",
              " 'hrnet_w44',\n",
              " 'hrnet_w48',\n",
              " 'hrnet_w64',\n",
              " 'ig_resnext101_32x8d',\n",
              " 'ig_resnext101_32x16d',\n",
              " 'ig_resnext101_32x32d',\n",
              " 'ig_resnext101_32x48d',\n",
              " 'inception_resnet_v2',\n",
              " 'inception_v3',\n",
              " 'inception_v4',\n",
              " 'lambda_resnet26t',\n",
              " 'lambda_resnet50t',\n",
              " 'legacy_senet154',\n",
              " 'legacy_seresnet18',\n",
              " 'legacy_seresnet34',\n",
              " 'legacy_seresnet50',\n",
              " 'legacy_seresnet101',\n",
              " 'legacy_seresnet152',\n",
              " 'legacy_seresnext26_32x4d',\n",
              " 'legacy_seresnext50_32x4d',\n",
              " 'legacy_seresnext101_32x4d',\n",
              " 'levit_128',\n",
              " 'levit_128s',\n",
              " 'levit_192',\n",
              " 'levit_256',\n",
              " 'levit_384',\n",
              " 'mixer_b16_224',\n",
              " 'mixer_b16_224_in21k',\n",
              " 'mixer_b16_224_miil',\n",
              " 'mixer_b16_224_miil_in21k',\n",
              " 'mixer_b32_224',\n",
              " 'mixer_l16_224',\n",
              " 'mixer_l16_224_in21k',\n",
              " 'mixer_l32_224',\n",
              " 'mixer_s16_224',\n",
              " 'mixer_s32_224',\n",
              " 'mixnet_l',\n",
              " 'mixnet_m',\n",
              " 'mixnet_s',\n",
              " 'mixnet_xl',\n",
              " 'mixnet_xxl',\n",
              " 'mnasnet_050',\n",
              " 'mnasnet_075',\n",
              " 'mnasnet_100',\n",
              " 'mnasnet_140',\n",
              " 'mnasnet_a1',\n",
              " 'mnasnet_b1',\n",
              " 'mnasnet_small',\n",
              " 'mobilenetv2_100',\n",
              " 'mobilenetv2_110d',\n",
              " 'mobilenetv2_120d',\n",
              " 'mobilenetv2_140',\n",
              " 'mobilenetv3_large_075',\n",
              " 'mobilenetv3_large_100',\n",
              " 'mobilenetv3_large_100_miil',\n",
              " 'mobilenetv3_large_100_miil_in21k',\n",
              " 'mobilenetv3_rw',\n",
              " 'mobilenetv3_small_075',\n",
              " 'mobilenetv3_small_100',\n",
              " 'nasnetalarge',\n",
              " 'nf_ecaresnet26',\n",
              " 'nf_ecaresnet50',\n",
              " 'nf_ecaresnet101',\n",
              " 'nf_regnet_b0',\n",
              " 'nf_regnet_b1',\n",
              " 'nf_regnet_b2',\n",
              " 'nf_regnet_b3',\n",
              " 'nf_regnet_b4',\n",
              " 'nf_regnet_b5',\n",
              " 'nf_resnet26',\n",
              " 'nf_resnet50',\n",
              " 'nf_resnet101',\n",
              " 'nf_seresnet26',\n",
              " 'nf_seresnet50',\n",
              " 'nf_seresnet101',\n",
              " 'nfnet_f0',\n",
              " 'nfnet_f0s',\n",
              " 'nfnet_f1',\n",
              " 'nfnet_f1s',\n",
              " 'nfnet_f2',\n",
              " 'nfnet_f2s',\n",
              " 'nfnet_f3',\n",
              " 'nfnet_f3s',\n",
              " 'nfnet_f4',\n",
              " 'nfnet_f4s',\n",
              " 'nfnet_f5',\n",
              " 'nfnet_f5s',\n",
              " 'nfnet_f6',\n",
              " 'nfnet_f6s',\n",
              " 'nfnet_f7',\n",
              " 'nfnet_f7s',\n",
              " 'nfnet_l0',\n",
              " 'pit_b_224',\n",
              " 'pit_b_distilled_224',\n",
              " 'pit_s_224',\n",
              " 'pit_s_distilled_224',\n",
              " 'pit_ti_224',\n",
              " 'pit_ti_distilled_224',\n",
              " 'pit_xs_224',\n",
              " 'pit_xs_distilled_224',\n",
              " 'pnasnet5large',\n",
              " 'rednet26t',\n",
              " 'rednet50ts',\n",
              " 'regnetx_002',\n",
              " 'regnetx_004',\n",
              " 'regnetx_006',\n",
              " 'regnetx_008',\n",
              " 'regnetx_016',\n",
              " 'regnetx_032',\n",
              " 'regnetx_040',\n",
              " 'regnetx_064',\n",
              " 'regnetx_080',\n",
              " 'regnetx_120',\n",
              " 'regnetx_160',\n",
              " 'regnetx_320',\n",
              " 'regnety_002',\n",
              " 'regnety_004',\n",
              " 'regnety_006',\n",
              " 'regnety_008',\n",
              " 'regnety_016',\n",
              " 'regnety_032',\n",
              " 'regnety_040',\n",
              " 'regnety_064',\n",
              " 'regnety_080',\n",
              " 'regnety_120',\n",
              " 'regnety_160',\n",
              " 'regnety_320',\n",
              " 'repvgg_a2',\n",
              " 'repvgg_b0',\n",
              " 'repvgg_b1',\n",
              " 'repvgg_b1g4',\n",
              " 'repvgg_b2',\n",
              " 'repvgg_b2g4',\n",
              " 'repvgg_b3',\n",
              " 'repvgg_b3g4',\n",
              " 'res2net50_14w_8s',\n",
              " 'res2net50_26w_4s',\n",
              " 'res2net50_26w_6s',\n",
              " 'res2net50_26w_8s',\n",
              " 'res2net50_48w_2s',\n",
              " 'res2net101_26w_4s',\n",
              " 'res2next50',\n",
              " 'resmlp_12_224',\n",
              " 'resmlp_12_distilled_224',\n",
              " 'resmlp_24_224',\n",
              " 'resmlp_24_distilled_224',\n",
              " 'resmlp_36_224',\n",
              " 'resmlp_36_distilled_224',\n",
              " 'resmlp_big_24_224',\n",
              " 'resmlp_big_24_224_in22ft1k',\n",
              " 'resmlp_big_24_distilled_224',\n",
              " 'resnest14d',\n",
              " 'resnest26d',\n",
              " 'resnest50d',\n",
              " 'resnest50d_1s4x24d',\n",
              " 'resnest50d_4s2x40d',\n",
              " 'resnest101e',\n",
              " 'resnest200e',\n",
              " 'resnest269e',\n",
              " 'resnet18',\n",
              " 'resnet18d',\n",
              " 'resnet26',\n",
              " 'resnet26d',\n",
              " 'resnet26t',\n",
              " 'resnet34',\n",
              " 'resnet34d',\n",
              " 'resnet50',\n",
              " 'resnet50d',\n",
              " 'resnet50t',\n",
              " 'resnet51q',\n",
              " 'resnet61q',\n",
              " 'resnet101',\n",
              " 'resnet101d',\n",
              " 'resnet152',\n",
              " 'resnet152d',\n",
              " 'resnet200',\n",
              " 'resnet200d',\n",
              " 'resnetblur18',\n",
              " 'resnetblur50',\n",
              " 'resnetrs50',\n",
              " 'resnetrs101',\n",
              " 'resnetrs152',\n",
              " 'resnetrs200',\n",
              " 'resnetrs270',\n",
              " 'resnetrs350',\n",
              " 'resnetrs420',\n",
              " 'resnetv2_50',\n",
              " 'resnetv2_50d',\n",
              " 'resnetv2_50t',\n",
              " 'resnetv2_50x1_bit_distilled',\n",
              " 'resnetv2_50x1_bitm',\n",
              " 'resnetv2_50x1_bitm_in21k',\n",
              " 'resnetv2_50x3_bitm',\n",
              " 'resnetv2_50x3_bitm_in21k',\n",
              " 'resnetv2_101',\n",
              " 'resnetv2_101d',\n",
              " 'resnetv2_101x1_bitm',\n",
              " 'resnetv2_101x1_bitm_in21k',\n",
              " 'resnetv2_101x3_bitm',\n",
              " 'resnetv2_101x3_bitm_in21k',\n",
              " 'resnetv2_152',\n",
              " 'resnetv2_152d',\n",
              " 'resnetv2_152x2_bit_teacher',\n",
              " 'resnetv2_152x2_bit_teacher_384',\n",
              " 'resnetv2_152x2_bitm',\n",
              " 'resnetv2_152x2_bitm_in21k',\n",
              " 'resnetv2_152x4_bitm',\n",
              " 'resnetv2_152x4_bitm_in21k',\n",
              " 'resnext50_32x4d',\n",
              " 'resnext50d_32x4d',\n",
              " 'resnext101_32x4d',\n",
              " 'resnext101_32x8d',\n",
              " 'resnext101_64x4d',\n",
              " 'rexnet_100',\n",
              " 'rexnet_130',\n",
              " 'rexnet_150',\n",
              " 'rexnet_200',\n",
              " 'rexnetr_100',\n",
              " 'rexnetr_130',\n",
              " 'rexnetr_150',\n",
              " 'rexnetr_200',\n",
              " 'selecsls42',\n",
              " 'selecsls42b',\n",
              " 'selecsls60',\n",
              " 'selecsls60b',\n",
              " 'selecsls84',\n",
              " 'semnasnet_050',\n",
              " 'semnasnet_075',\n",
              " 'semnasnet_100',\n",
              " 'semnasnet_140',\n",
              " 'senet154',\n",
              " 'seresnet18',\n",
              " 'seresnet34',\n",
              " 'seresnet50',\n",
              " 'seresnet50t',\n",
              " 'seresnet101',\n",
              " 'seresnet152',\n",
              " 'seresnet152d',\n",
              " 'seresnet200d',\n",
              " 'seresnet269d',\n",
              " 'seresnext26d_32x4d',\n",
              " 'seresnext26t_32x4d',\n",
              " 'seresnext26tn_32x4d',\n",
              " 'seresnext50_32x4d',\n",
              " 'seresnext101_32x4d',\n",
              " 'seresnext101_32x8d',\n",
              " 'skresnet18',\n",
              " 'skresnet34',\n",
              " 'skresnet50',\n",
              " 'skresnet50d',\n",
              " 'skresnext50_32x4d',\n",
              " 'spnasnet_100',\n",
              " 'ssl_resnet18',\n",
              " 'ssl_resnet50',\n",
              " 'ssl_resnext50_32x4d',\n",
              " 'ssl_resnext101_32x4d',\n",
              " 'ssl_resnext101_32x8d',\n",
              " 'ssl_resnext101_32x16d',\n",
              " 'swin_base_patch4_window7_224',\n",
              " 'swin_base_patch4_window7_224_in22k',\n",
              " 'swin_base_patch4_window12_384',\n",
              " 'swin_base_patch4_window12_384_in22k',\n",
              " 'swin_large_patch4_window7_224',\n",
              " 'swin_large_patch4_window7_224_in22k',\n",
              " 'swin_large_patch4_window12_384',\n",
              " 'swin_large_patch4_window12_384_in22k',\n",
              " 'swin_small_patch4_window7_224',\n",
              " 'swin_tiny_patch4_window7_224',\n",
              " 'swinnet26t_256',\n",
              " 'swinnet50ts_256',\n",
              " 'swsl_resnet18',\n",
              " 'swsl_resnet50',\n",
              " 'swsl_resnext50_32x4d',\n",
              " 'swsl_resnext101_32x4d',\n",
              " 'swsl_resnext101_32x8d',\n",
              " 'swsl_resnext101_32x16d',\n",
              " 'tf_efficientnet_b0',\n",
              " 'tf_efficientnet_b0_ap',\n",
              " 'tf_efficientnet_b0_ns',\n",
              " 'tf_efficientnet_b1',\n",
              " 'tf_efficientnet_b1_ap',\n",
              " 'tf_efficientnet_b1_ns',\n",
              " 'tf_efficientnet_b2',\n",
              " 'tf_efficientnet_b2_ap',\n",
              " 'tf_efficientnet_b2_ns',\n",
              " 'tf_efficientnet_b3',\n",
              " 'tf_efficientnet_b3_ap',\n",
              " 'tf_efficientnet_b3_ns',\n",
              " 'tf_efficientnet_b4',\n",
              " 'tf_efficientnet_b4_ap',\n",
              " 'tf_efficientnet_b4_ns',\n",
              " 'tf_efficientnet_b5',\n",
              " 'tf_efficientnet_b5_ap',\n",
              " 'tf_efficientnet_b5_ns',\n",
              " 'tf_efficientnet_b6',\n",
              " 'tf_efficientnet_b6_ap',\n",
              " 'tf_efficientnet_b6_ns',\n",
              " 'tf_efficientnet_b7',\n",
              " 'tf_efficientnet_b7_ap',\n",
              " 'tf_efficientnet_b7_ns',\n",
              " 'tf_efficientnet_b8',\n",
              " 'tf_efficientnet_b8_ap',\n",
              " 'tf_efficientnet_cc_b0_4e',\n",
              " 'tf_efficientnet_cc_b0_8e',\n",
              " 'tf_efficientnet_cc_b1_8e',\n",
              " 'tf_efficientnet_el',\n",
              " 'tf_efficientnet_em',\n",
              " 'tf_efficientnet_es',\n",
              " 'tf_efficientnet_l2_ns',\n",
              " 'tf_efficientnet_l2_ns_475',\n",
              " 'tf_efficientnet_lite0',\n",
              " 'tf_efficientnet_lite1',\n",
              " 'tf_efficientnet_lite2',\n",
              " 'tf_efficientnet_lite3',\n",
              " 'tf_efficientnet_lite4',\n",
              " 'tf_efficientnetv2_b0',\n",
              " 'tf_efficientnetv2_b1',\n",
              " 'tf_efficientnetv2_b2',\n",
              " 'tf_efficientnetv2_b3',\n",
              " 'tf_efficientnetv2_l',\n",
              " 'tf_efficientnetv2_l_in21ft1k',\n",
              " 'tf_efficientnetv2_l_in21k',\n",
              " 'tf_efficientnetv2_m',\n",
              " 'tf_efficientnetv2_m_in21ft1k',\n",
              " 'tf_efficientnetv2_m_in21k',\n",
              " 'tf_efficientnetv2_s',\n",
              " 'tf_efficientnetv2_s_in21ft1k',\n",
              " 'tf_efficientnetv2_s_in21k',\n",
              " 'tf_inception_v3',\n",
              " 'tf_mixnet_l',\n",
              " 'tf_mixnet_m',\n",
              " 'tf_mixnet_s',\n",
              " 'tf_mobilenetv3_large_075',\n",
              " 'tf_mobilenetv3_large_100',\n",
              " 'tf_mobilenetv3_large_minimal_100',\n",
              " 'tf_mobilenetv3_small_075',\n",
              " 'tf_mobilenetv3_small_100',\n",
              " 'tf_mobilenetv3_small_minimal_100',\n",
              " 'tnt_b_patch16_224',\n",
              " 'tnt_s_patch16_224',\n",
              " 'tresnet_l',\n",
              " 'tresnet_l_448',\n",
              " 'tresnet_m',\n",
              " 'tresnet_m_448',\n",
              " 'tresnet_m_miil_in21k',\n",
              " 'tresnet_xl',\n",
              " 'tresnet_xl_448',\n",
              " 'tv_densenet121',\n",
              " 'tv_resnet34',\n",
              " 'tv_resnet50',\n",
              " 'tv_resnet101',\n",
              " 'tv_resnet152',\n",
              " 'tv_resnext50_32x4d',\n",
              " 'twins_pcpvt_base',\n",
              " 'twins_pcpvt_large',\n",
              " 'twins_pcpvt_small',\n",
              " 'twins_svt_base',\n",
              " 'twins_svt_large',\n",
              " 'twins_svt_small',\n",
              " 'vgg11',\n",
              " 'vgg11_bn',\n",
              " 'vgg13',\n",
              " 'vgg13_bn',\n",
              " 'vgg16',\n",
              " 'vgg16_bn',\n",
              " 'vgg19',\n",
              " 'vgg19_bn',\n",
              " 'visformer_small',\n",
              " 'visformer_tiny',\n",
              " 'vit_base_patch16_224',\n",
              " 'vit_base_patch16_224_in21k',\n",
              " 'vit_base_patch16_224_miil',\n",
              " 'vit_base_patch16_224_miil_in21k',\n",
              " 'vit_base_patch16_384',\n",
              " 'vit_base_patch32_224',\n",
              " 'vit_base_patch32_224_in21k',\n",
              " 'vit_base_patch32_384',\n",
              " 'vit_base_r26_s32_224',\n",
              " 'vit_base_r50_s16_224',\n",
              " 'vit_base_r50_s16_224_in21k',\n",
              " 'vit_base_r50_s16_384',\n",
              " 'vit_base_resnet26d_224',\n",
              " 'vit_base_resnet50_224_in21k',\n",
              " 'vit_base_resnet50_384',\n",
              " 'vit_base_resnet50d_224',\n",
              " 'vit_huge_patch14_224_in21k',\n",
              " 'vit_large_patch16_224',\n",
              " 'vit_large_patch16_224_in21k',\n",
              " 'vit_large_patch16_384',\n",
              " 'vit_large_patch32_224',\n",
              " 'vit_large_patch32_224_in21k',\n",
              " 'vit_large_patch32_384',\n",
              " 'vit_large_r50_s32_224',\n",
              " 'vit_large_r50_s32_224_in21k',\n",
              " 'vit_large_r50_s32_384',\n",
              " 'vit_small_patch16_224',\n",
              " 'vit_small_patch16_224_in21k',\n",
              " 'vit_small_patch16_384',\n",
              " 'vit_small_patch32_224',\n",
              " 'vit_small_patch32_224_in21k',\n",
              " 'vit_small_patch32_384',\n",
              " 'vit_small_r26_s32_224',\n",
              " 'vit_small_r26_s32_224_in21k',\n",
              " 'vit_small_r26_s32_384',\n",
              " 'vit_small_resnet26d_224',\n",
              " 'vit_small_resnet50d_s16_224',\n",
              " 'vit_tiny_patch16_224',\n",
              " 'vit_tiny_patch16_224_in21k',\n",
              " 'vit_tiny_patch16_384',\n",
              " 'vit_tiny_r_s16_p8_224',\n",
              " 'vit_tiny_r_s16_p8_224_in21k',\n",
              " 'vit_tiny_r_s16_p8_384',\n",
              " 'vovnet39a',\n",
              " 'vovnet57a',\n",
              " 'wide_resnet50_2',\n",
              " 'wide_resnet101_2',\n",
              " 'xception',\n",
              " 'xception41',\n",
              " 'xception65',\n",
              " 'xception71']"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_Q9XR_zsQEJb",
        "outputId": "4d71bf08-164e-46ee-f727-05d33448f0be"
      },
      "source": [
        "import torch.optim as optim\n",
        "\n",
        "name = 'tf_efficientnet_b0_ns'\n",
        "\n",
        "### <모델 고르기> (검색용) ##########################################################################################################\n",
        "### 학습에 사용할 인공지능 모델을 골라준다.\n",
        "### 아래 주석을 해제하여 사용\n",
        "### \n",
        "### PretrainedTransformer 사용하는 방법\n",
        "### 1. 아래 \"model = PretrainedTransformer..\" 가 있는 줄의 주석을 해제한다.\n",
        "### 2. 아까 위에서 <학습된 모델 확인하기>에서 출력된 모델 중 하나를 고른다.\n",
        "### 3. 아래 (학습된 모델 이름) 에 넣어준다.\n",
        "#####################################################################################################################################\n",
        "#model = PretrainedCNN(use_meta = True)                                          ### PretrainedCNN(resnet모델) 을 사용하는 경우\n",
        "#model = BaseCNN(num_filters=[4,5,6,7,8], use_meta = True)                                                ### BaseCNN 을 사용하는 경우\n",
        "#model = BaseMLP(use_meta = True)                                                ### BaseMLP 를 사용하는 경우\n",
        "model = PretrainedTransformer(model_name='seresnet50', use_meta = True) ### PretrainedTransformer 을 사용하는 경우 \n",
        "\n",
        "\n",
        "params_to_update = model.parameters()\n",
        "print(\"Params to learn:\")\n",
        "if args.feature_extract:\n",
        "    params_to_update = []\n",
        "    for name,param in model.named_parameters():\n",
        "        if param.requires_grad == True:\n",
        "            params_to_update.append(param)\n",
        "            print(\"\\t\",name)\n",
        "else:\n",
        "    for name,param in model.named_parameters():\n",
        "        if param.requires_grad == True:\n",
        "            print(\"\\t\",name)\n",
        "\n",
        "### <optimizer 설정하는 곳> (검색용) ########################################################################\n",
        "### 지금은 optim.Adam 으로 설정되어있음. optim.Adam 대신 다른 optimizer 알고리즘으로 바꿀수 있다.\n",
        "###\n",
        "### 다른 optimizer들 : optim.Adadelta , optim.Adagrad, optim.AdamW 등등\n",
        "### 다른 optimizer로 바꾸려면, 해당 optimizer 알고리즘에 필요한 인자들을 알맞게 넣어줘야 한다. \n",
        "### 인자를 넣는 형식 등 자세한 사용법은 https://pytorch.org/docs/stable/optim.html 에 가서 \n",
        "### Algorithms 부분 밑에 알고리즘을 클릭해서 들어가면 알 수 있음.\n",
        "####################################################################################################\n",
        "learning_rate = 1e-3\n",
        "optimizer = optim.Adam(params_to_update, lr=learning_rate, amsgrad=False)\n",
        "model = nn.DataParallel(model).cuda()"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Params to learn:\n",
            "\t fc.weight\n",
            "\t fc.bias\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t27Uw_dax4Ea"
      },
      "source": [
        "##5  추가한 코드셀\n",
        "''' 9. 학습되는 과정 속에서 검증 데이터에 대한 모델 성능을 확인하는 함수 정의 '''\n",
        "def evaluate(model, test_loader):\n",
        "    model.eval()\n",
        "    test_loss = 0\n",
        "    #correct = 0\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for image, label in test_loader:\n",
        "            image = image.to(DEVICE)\n",
        "            label = label.to(DEVICE)\n",
        "            output = model(image)\n",
        "            test_loss += mse(output, label).item()\n",
        "    \n",
        "    test_loss /= (len(test_loader.dataset) / args.batch_size)\n",
        "\n",
        "    return test_loss"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "51j3bHixQFzc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a3fc1769-d1c6-42ce-ba8a-8377c6be95fe"
      },
      "source": [
        "# # Train & val the model\n",
        "best_score = 0\n",
        "epochs = args.epochs\n",
        "\n",
        "\n",
        "\n",
        "for epoch in range(epochs):\n",
        "    labels, pred = train(model, optimizer, trainval_loader, None, train=True, val=False, epoch=epoch, grad_clip=True)\n",
        "\n",
        "    torch.save({\"model\": model.state_dict()}, \"efficient_model.pth\")"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "train E000:   1% 1/155 [00:16<41:44, 16.26s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\tTrain Epoch:0 \tTrain Loss(RMSE): 43.950927\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "train E000:   7% 11/155 [00:32<05:30,  2.30s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\tTrain Epoch:0 \tTrain Loss(RMSE): 43.400738\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "train E000:  14% 21/155 [00:52<05:14,  2.35s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\tTrain Epoch:0 \tTrain Loss(RMSE): 43.104793\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "train E000:  20% 31/155 [01:13<04:51,  2.35s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\tTrain Epoch:0 \tTrain Loss(RMSE): 34.780920\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "train E000:  26% 41/155 [01:34<04:28,  2.35s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\tTrain Epoch:0 \tTrain Loss(RMSE): 32.882199\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "train E000:  33% 51/155 [01:55<04:07,  2.38s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\tTrain Epoch:0 \tTrain Loss(RMSE): 28.749704\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "train E000:  39% 61/155 [02:16<03:47,  2.42s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\tTrain Epoch:0 \tTrain Loss(RMSE): 20.055083\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "train E000:  46% 71/155 [02:38<03:25,  2.45s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\tTrain Epoch:0 \tTrain Loss(RMSE): 26.042775\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "train E000:  52% 81/155 [02:59<03:00,  2.44s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\tTrain Epoch:0 \tTrain Loss(RMSE): 24.502272\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "train E000:  59% 91/155 [03:21<02:37,  2.46s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\tTrain Epoch:0 \tTrain Loss(RMSE): 20.763781\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "train E000:  65% 101/155 [03:44<02:16,  2.53s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\tTrain Epoch:0 \tTrain Loss(RMSE): 23.791139\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "train E000:  72% 111/155 [04:07<01:53,  2.57s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\tTrain Epoch:0 \tTrain Loss(RMSE): 24.945644\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "train E000:  78% 121/155 [04:29<01:27,  2.58s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\tTrain Epoch:0 \tTrain Loss(RMSE): 17.697656\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "train E000:  85% 131/155 [04:52<01:02,  2.59s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\tTrain Epoch:0 \tTrain Loss(RMSE): 26.104241\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "train E000:  91% 141/155 [05:16<00:37,  2.65s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\tTrain Epoch:0 \tTrain Loss(RMSE): 24.122599\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "train E000:  97% 151/155 [05:40<00:10,  2.64s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\tTrain Epoch:0 \tTrain Loss(RMSE): 20.018294\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "train E000: 100% 155/155 [05:58<00:00,  2.32s/it]\n",
            "train E001:   1% 1/155 [00:05<14:35,  5.68s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\tTrain Epoch:1 \tTrain Loss(RMSE): 19.601461\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "train E001:   7% 11/155 [00:25<06:05,  2.54s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\tTrain Epoch:1 \tTrain Loss(RMSE): 19.856480\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "train E001:  14% 22/155 [00:44<03:49,  1.72s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\tTrain Epoch:1 \tTrain Loss(RMSE): 22.300979\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "train E001:  20% 31/155 [01:02<04:35,  2.22s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\tTrain Epoch:1 \tTrain Loss(RMSE): 26.770028\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "train E001:  26% 41/155 [01:20<04:08,  2.18s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\tTrain Epoch:1 \tTrain Loss(RMSE): 20.593048\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "train E001:  33% 51/155 [01:39<03:49,  2.21s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\tTrain Epoch:1 \tTrain Loss(RMSE): 20.289851\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "train E001:  39% 61/155 [01:57<03:24,  2.18s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\tTrain Epoch:1 \tTrain Loss(RMSE): 23.543798\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "train E001:  46% 71/155 [02:15<03:06,  2.22s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\tTrain Epoch:1 \tTrain Loss(RMSE): 18.486740\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "train E001:  52% 81/155 [02:35<02:50,  2.30s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\tTrain Epoch:1 \tTrain Loss(RMSE): 20.240865\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "train E001:  59% 91/155 [02:55<02:28,  2.33s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\tTrain Epoch:1 \tTrain Loss(RMSE): 18.256472\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "train E001:  65% 101/155 [03:15<02:08,  2.38s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\tTrain Epoch:1 \tTrain Loss(RMSE): 19.104035\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "train E001:  72% 111/155 [03:36<01:43,  2.36s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\tTrain Epoch:1 \tTrain Loss(RMSE): 21.442974\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "train E001:  78% 121/155 [03:56<01:21,  2.40s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\tTrain Epoch:1 \tTrain Loss(RMSE): 21.968097\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "train E001:  85% 131/155 [04:16<00:56,  2.36s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\tTrain Epoch:1 \tTrain Loss(RMSE): 21.003252\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "train E001:  91% 141/155 [04:37<00:32,  2.33s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\tTrain Epoch:1 \tTrain Loss(RMSE): 21.932916\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "train E001:  97% 151/155 [04:58<00:09,  2.33s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\tTrain Epoch:1 \tTrain Loss(RMSE): 21.191368\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "train E001: 100% 155/155 [05:04<00:00,  1.96s/it]\n",
            "train E002:   1% 1/155 [00:05<14:53,  5.80s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\tTrain Epoch:2 \tTrain Loss(RMSE): 22.380818\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "train E002:   7% 11/155 [00:25<05:50,  2.43s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\tTrain Epoch:2 \tTrain Loss(RMSE): 21.895210\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "train E002:  14% 21/155 [00:44<05:16,  2.36s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\tTrain Epoch:2 \tTrain Loss(RMSE): 18.728307\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "train E002:  20% 31/155 [01:03<04:57,  2.40s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\tTrain Epoch:2 \tTrain Loss(RMSE): 18.209123\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "train E002:  27% 42/155 [01:22<03:18,  1.76s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\tTrain Epoch:2 \tTrain Loss(RMSE): 18.757219\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "train E002:  34% 52/155 [01:41<02:53,  1.68s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\tTrain Epoch:2 \tTrain Loss(RMSE): 18.435441\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "train E002:  40% 62/155 [02:00<02:33,  1.65s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\tTrain Epoch:2 \tTrain Loss(RMSE): 20.259372\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "train E002:  46% 71/155 [02:18<03:20,  2.38s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\tTrain Epoch:2 \tTrain Loss(RMSE): 16.131843\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "train E002:  52% 81/155 [02:38<02:55,  2.37s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\tTrain Epoch:2 \tTrain Loss(RMSE): 24.425541\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "train E002:  59% 92/155 [02:57<01:48,  1.73s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\tTrain Epoch:2 \tTrain Loss(RMSE): 27.266059\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "train E002:  65% 101/155 [03:17<02:14,  2.48s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\tTrain Epoch:2 \tTrain Loss(RMSE): 25.232072\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "train E002:  72% 111/155 [03:36<01:50,  2.50s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\tTrain Epoch:2 \tTrain Loss(RMSE): 23.716693\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "train E002:  78% 121/155 [03:56<01:25,  2.52s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\tTrain Epoch:2 \tTrain Loss(RMSE): 20.396694\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "train E002:  85% 131/155 [04:16<00:59,  2.48s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\tTrain Epoch:2 \tTrain Loss(RMSE): 20.084736\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "train E002:  92% 142/155 [04:36<00:23,  1.80s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\tTrain Epoch:2 \tTrain Loss(RMSE): 24.412957\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "train E002:  97% 151/155 [04:55<00:09,  2.46s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\tTrain Epoch:2 \tTrain Loss(RMSE): 19.683052\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "train E002: 100% 155/155 [05:00<00:00,  1.94s/it]\n",
            "train E003:   1% 1/155 [00:05<14:51,  5.79s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\tTrain Epoch:3 \tTrain Loss(RMSE): 23.711950\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "train E003:   7% 11/155 [00:27<07:24,  3.09s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\tTrain Epoch:3 \tTrain Loss(RMSE): 16.508482\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "train E003:  14% 21/155 [00:46<05:30,  2.46s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\tTrain Epoch:3 \tTrain Loss(RMSE): 24.929258\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "train E003:  20% 31/155 [01:06<05:03,  2.45s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\tTrain Epoch:3 \tTrain Loss(RMSE): 20.963181\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "train E003:  27% 42/155 [01:25<03:15,  1.73s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\tTrain Epoch:3 \tTrain Loss(RMSE): 19.839180\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "train E003:  33% 51/155 [01:44<04:07,  2.38s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\tTrain Epoch:3 \tTrain Loss(RMSE): 21.833898\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "train E003:  40% 62/155 [02:01<02:27,  1.59s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\tTrain Epoch:3 \tTrain Loss(RMSE): 20.223421\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "train E003:  46% 71/155 [02:19<03:07,  2.23s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\tTrain Epoch:3 \tTrain Loss(RMSE): 19.251417\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "train E003:  53% 82/155 [02:37<01:57,  1.61s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\tTrain Epoch:3 \tTrain Loss(RMSE): 17.311382\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "train E003:  59% 91/155 [02:55<02:24,  2.26s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\tTrain Epoch:3 \tTrain Loss(RMSE): 19.749296\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "train E003:  65% 101/155 [03:14<02:02,  2.27s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\tTrain Epoch:3 \tTrain Loss(RMSE): 21.859613\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "train E003:  72% 111/155 [03:31<01:34,  2.15s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\tTrain Epoch:3 \tTrain Loss(RMSE): 19.871936\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "train E003:  78% 121/155 [03:48<01:13,  2.17s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\tTrain Epoch:3 \tTrain Loss(RMSE): 15.666626\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "train E003:  85% 131/155 [04:06<00:52,  2.19s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\tTrain Epoch:3 \tTrain Loss(RMSE): 22.786264\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "train E003:  91% 141/155 [04:23<00:30,  2.19s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\tTrain Epoch:3 \tTrain Loss(RMSE): 23.287814\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "train E003:  97% 151/155 [04:41<00:08,  2.17s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\tTrain Epoch:3 \tTrain Loss(RMSE): 19.598389\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "train E003: 100% 155/155 [04:46<00:00,  1.85s/it]\n",
            "train E004:   1% 1/155 [00:05<13:55,  5.43s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\tTrain Epoch:4 \tTrain Loss(RMSE): 15.823189\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "train E004:   7% 11/155 [00:23<05:35,  2.33s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\tTrain Epoch:4 \tTrain Loss(RMSE): 20.336801\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "train E004:  14% 21/155 [00:41<04:59,  2.23s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\tTrain Epoch:4 \tTrain Loss(RMSE): 22.471252\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "train E004:  21% 32/155 [00:59<03:19,  1.62s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\tTrain Epoch:4 \tTrain Loss(RMSE): 21.345423\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "train E004:  26% 41/155 [01:16<04:07,  2.17s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\tTrain Epoch:4 \tTrain Loss(RMSE): 24.040351\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "train E004:  33% 51/155 [01:34<03:37,  2.10s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\tTrain Epoch:4 \tTrain Loss(RMSE): 17.668467\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "train E004:  39% 61/155 [01:52<03:22,  2.16s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\tTrain Epoch:4 \tTrain Loss(RMSE): 21.348022\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "train E004:  46% 71/155 [02:10<03:03,  2.18s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\tTrain Epoch:4 \tTrain Loss(RMSE): 25.352777\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "train E004:  52% 81/155 [02:28<02:41,  2.19s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\tTrain Epoch:4 \tTrain Loss(RMSE): 24.877922\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "train E004:  59% 91/155 [02:47<02:22,  2.23s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\tTrain Epoch:4 \tTrain Loss(RMSE): 20.126777\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "train E004:  65% 101/155 [03:05<01:58,  2.19s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\tTrain Epoch:4 \tTrain Loss(RMSE): 20.212879\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "train E004:  72% 111/155 [03:24<01:37,  2.22s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\tTrain Epoch:4 \tTrain Loss(RMSE): 17.809740\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "train E004:  78% 121/155 [03:43<01:17,  2.28s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\tTrain Epoch:4 \tTrain Loss(RMSE): 22.772733\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "train E004:  85% 131/155 [04:02<00:53,  2.22s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\tTrain Epoch:4 \tTrain Loss(RMSE): 17.516744\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "train E004:  91% 141/155 [04:21<00:30,  2.18s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\tTrain Epoch:4 \tTrain Loss(RMSE): 19.551495\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "train E004:  97% 151/155 [04:39<00:08,  2.16s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\tTrain Epoch:4 \tTrain Loss(RMSE): 24.137065\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "train E004: 100% 155/155 [04:45<00:00,  1.84s/it]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J2Ea9t1bQMJT",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6aa526b0-027f-438c-9d42-d60e563c89e0"
      },
      "source": [
        "# Test the model\n",
        "logs = torch.load(\"./efficient_model.pth\")\n",
        "model.load_state_dict(logs['model'])\n",
        "_, pred = train(model, optimizer, None, test_loader, train=False, val=True, epoch=0, grad_clip=False)\n",
        "print(\"Pawpularity score:{}\".format(pred.mean().item()))\n",
        "\n",
        "submission = pd.DataFrame({'Id':test_id,'Pawpularity':pred.squeeze(1)})"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "val E000: 100% 1/1 [00:06<00:00,  6.59s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Pawpularity score:9.834451675415039\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UTjkH0BJXpUt",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 300
        },
        "outputId": "d15670e7-25f1-49fc-9d06-ffbad3e02dd2"
      },
      "source": [
        "submission"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Id</th>\n",
              "      <th>Pawpularity</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>4128bae22183829d2b5fea10effdb0c3</td>\n",
              "      <td>10.284771</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>43a2262d7738e3d420d453815151079e</td>\n",
              "      <td>8.728458</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>4e429cead1848a298432a0acad014c9d</td>\n",
              "      <td>9.028299</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>80bc3ccafcc51b66303c2c263aa38486</td>\n",
              "      <td>9.944561</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>8f49844c382931444e68dffbe20228f4</td>\n",
              "      <td>10.765824</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>b03f7041962238a7c9d6537e22f9b017</td>\n",
              "      <td>11.358576</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>c978013571258ed6d4637f6e8cc9d6a3</td>\n",
              "      <td>8.948625</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>e0de453c1bffc20c22b072b34b54e50f</td>\n",
              "      <td>9.616496</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                 Id  Pawpularity\n",
              "0  4128bae22183829d2b5fea10effdb0c3    10.284771\n",
              "1  43a2262d7738e3d420d453815151079e     8.728458\n",
              "2  4e429cead1848a298432a0acad014c9d     9.028299\n",
              "3  80bc3ccafcc51b66303c2c263aa38486     9.944561\n",
              "4  8f49844c382931444e68dffbe20228f4    10.765824\n",
              "5  b03f7041962238a7c9d6537e22f9b017    11.358576\n",
              "6  c978013571258ed6d4637f6e8cc9d6a3     8.948625\n",
              "7  e0de453c1bffc20c22b072b34b54e50f     9.616496"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OEuaagupacpy",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 387
        },
        "outputId": "df49b55b-f833-4b7e-89bc-5fbe143a146f"
      },
      "source": [
        "##5\n",
        "# test loss를 plotting 하기 위한 코드#########\n",
        "plt.figure(figsize=(10,5))\n",
        "plt.title(\"Test Loss\")\n",
        "plt.plot(test_loss_record, label=\"model 1\")\n",
        "plt.xlabel(\"batch\")\n",
        "plt.ylabel(\"Loss\")\n",
        "plt.legend()\n",
        "plt.show()\n",
        "\n",
        "### <RMSE 평균값 구하는 곳 > (검색용) ################################################################\n",
        "### 지금은 RMSE 평균값 계산할때, RMSE 값들을 가장 마지막 \"10개\" 배치만을 이용하도록 되어있음\n",
        "### \n",
        "### RMSE 평균값 계산할때, RMSE 값들을 가장 마지막 \"n개\" 배치만을 이용하도록 하고 싶으면,\n",
        "### 아래 코드에서 \"-10\" 부분을, \"-n\" 으로 숫자를 바꿔주면 된다. \n",
        "#############################################################################################\n",
        "last_batch_avg_RMSE = sum(test_loss_record[-10:] ,0.0) / len(test_loss_record[-10:])\n",
        "print(\"\\nlast {} batch average RMSE = {}\".format(-(-10) ,last_batch_avg_RMSE))"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 720x360 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "last 10 batch average RMSE = 21.370615401377286\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cMz4DPKoKiYP"
      },
      "source": [
        "# <코드 수정 기록> \n",
        "# 2021.12.05(일) pm 3\n",
        "# loss 출력을 RMSE로 바꿈\n",
        "# 각 배치 마다 test loss 를 리스트로 저장해서, 학습완료후에 학습진행 그래프 출력되도록 코드 추가함\n",
        "# 평균 RMSE를 계산하기 위해서, 학습중 마지막 10개 배치의 RMSE의 평균값을 출력하도록 코드 추가함\n",
        "# 2021.12.05(일) pm 6\n",
        "# 하이퍼파라미터튜닝 할 수 있도록 중요 코드 부분 주석처리함"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kj4eYxM7bDCB"
      },
      "source": [
        ""
      ],
      "execution_count": 20,
      "outputs": []
    }
  ]
}